import HeadMeta from './components/head'
import { CodeSurfer } from "mdx-deck-code-surfer";
import duotoneDark from "prism-react-renderer/themes/duotoneDark"
import { Image } from 'mdx-deck'
import { HalfImage, ContainImage } from './components/image'
import Emoji from './components/emoji'
import { Invert, Split, SplitRight } from 'mdx-deck/layouts'

export { default as theme } from './theme'

<HeadMeta />

export default Invert

## A Guide to Testing Kafka
#### October, 2018

---
import Person from './components/person'
import matt from './assets/my-face.jpg'

<Person
  avatar={matt} 
  name="Matt Schroeder" 
  title="Senior Consultant, Object Partners" 
  logoHeight="40"
  linkedin="matthewschroeder3"
  github="msschroe3"
  />

---
export default Invert

import nondeterminism from './assets/nondeterminism.gif'

### You know the feeling..

<img 
  src={nondeterminism} 
  alt={'struggle bus'} 
  />

---
import { Appear } from 'mdx-deck'

## Goals

<ul style={{ textAlign: 'left' }}>
  <Appear>
    <li>Value of Testing</li>
    <li>Approaches to Testing</li>
    <li>Integration Testing Kafka</li>
    <li>Success Measures</li>
  </Appear>
</ul>
---

<ContainImage src='./assets/1-pyramid.png' />

```notes
https://martinfowler.com/articles/practical-test-pyramid.html

* roughly 70/20/10
```
---

<ContainImage src='./assets/2-pyramid-unit.png' />

---
export default Invert

## Unit tests should be..

<ul style={{ listStyleType: 'none', color: '#FEE56E'}}>
  <Appear>
    <li>
      <h3 style={{ margin: '5px' }}>
        Fast <Emoji symbol={'üèÉ'} label={'fast runner'}/>
      </h3>
    </li>
    <li>
      <h3 style={{ margin: '5px' }}>
        Reliable  <Emoji symbol={'üí™'} label={'strong and reliable'}/>
      </h3>
    </li>
    <li>
      <h3 style={{ margin: '5px' }}>
        Readable <Emoji symbol={'üìö'} label={'readable'}/>
      </h3>
    </li>
  </Appear>
</ul>

```notes
- Unit tests are fast. We only need to build a small unit to test it, and the tests also tend to be rather small. In fact, one tenth of a second is considered slow for unit tests. 
- Unit tests are reliable. Simple systems and small units in general tend to suffer much less from flakiness. Furthermore, best practices for unit testing - in particular practices related to hermetic tests - will remove flakiness entirely. 
- Unit tests isolate failures. Even if a product contains millions of lines of code, if a unit test fails, you only need to search that small unit under test to find the bug. 
- hermetic testing - each test should be completely independent and self-sufficient

**so why is it so hard to get those tests written? writing tests should be the easy part!
  - the part that makes or breaks your tests is... you guessed it, writing testable code
```
---

<CodeSurfer
  code={require("raw-loader!./snippets/spock-test.groovy")}
  language="groovy"
  title="Spock to the Rescue!"
  steps={[
    { range: [ 1,  23] },
    { range: [5, 8], notes: "Setup sut with mock(s)"},
    { range: [10, 22], notes: "A readable test structure"},
    { range: [11, 12], notes: "Given some condition(s)"},
    { range: [14, 15], notes: "When an action is performed"},
    { range: [17, 18], notes: "Then this thing should happen"},
    { range: [20, 21], notes: "And this should also be true"},
    { range: [10, 22]}
  ]}
/>

```notes
http://spockframework.org/spock/docs/1.2/spock_primer.html
```

---
export default SplitRight

<HalfImage src='./assets/great.jpg' />

## Testable Code

<ul style={{listStyleType: 'none', textAlign: 'left', marginLeft: '3em', color: '#E12B2E'}}>
  <li><Emoji symbol={'‚ùå'} label={'red x'} /> Static "Util" Methods</li>
  <li><Emoji symbol={'‚ùå'} label={'red x'} /> Manual Object Instantiation</li>
  <li><Emoji symbol={'‚ùå'} label={'red x'} /> Non-Deterministic Behavior</li>
</ul>

```notes
https://www.toptal.com/qa/how-to-write-testable-code-and-why-it-matters

- static code has to be tested along with the sut, so anytime the static code changes it could affect the sut without knowing it
  - this goes against testing isolated units of code
- similar to static methods, instantiating objects in a method leaves you no choice but to test that code alongside the sut
  - this also makes the "unit" tests very hard to write, read, maintain because they start to integrate with more and more things
- think functional, input->function->output - pumping the same inputs should always produce the same output.
```

---

<CodeSurfer
  code={require("raw-loader!./snippets/untestable.groovy")}
  language="groovy"
  title="Example"
  steps={[
    { range: [ 1,  10] },
    { lines: [3], notes: "Instantiated class" },
    { lines: [4], notes: "Nondeterministic functionality" },
    { lines: [6], notes: "A handy util" },
    { range: [12, 28], notes: "An alternative"},
    { range: [14, 19], notes: "Injected services"},
    { range: [12, 13], notes: "This service is available for injection!"},
    { tokens: { 21: [ 11 ] }, notes: "Remove nondeterminism" },
    { lines: [23], notes: "A utility you can mock" }
  ]}
/>

---

<ContainImage src='./assets/3-pyramid-integration.png' />

---
export default Invert

> Isolated code might not be cohesive.

```notes
Unit tests do have one major disadvantage: 
* even if the units work well in isolation, you do not know if they work well together. 
But even then, you do not necessarily need end-to-end tests. 
For that, you can use an integration test. An integration test takes a small 
group of units, often two units, and tests their behavior as a whole, 
verifying that they coherently work together.
```

---

<ContainImage src='./assets/units.png' />

---

<ContainImage src='./assets/units-and-integration.png' />

```notes
Unit testing can be easy given clean boundaries and some of the things we talked
about in the previous slide. But how do we start to bridge those boundaries and
test how things work together.
```
---

## Testing Kafka
* Manual
* Docker Compose / Confluent Platform
* Kafka Streams Test Utils
* Spring Kafka Test

```notes
There are a few ways to set up an environment conducive to writing integration tests, and although I‚Äôm only highlighting my preferred method there are pros/cons to whichever your team might land on so be sure to have those conversations and understand what you‚Äôre committing to before you actually do.

* Docker Compose
    * this gives you a little bit more realistic environment to test with
    * Slower to get going without some background
    * Slower to start up
* Spring Kafka Testing
    * Easy to pull in
    * Like other Spring Projects it gives an opinionated approach that nudges you in the right direction. Some engineers like this, some don‚Äôt.
    * Convenience annotations to get running immediately
    * Fast, in memory environment that IMO is realistic enough for the scenarios that integration tests should be running. Would I run performance tests against embedded kafka? Probably not.
* Everything Else
    * Confluent Ducktape
    * Cucumber
    * ‚Ä¶ testing framework xyz
```

---

<ContainImage src='./assets/streams-topology.png' />

---

## [Kafka Streams Test Utils](https://mvnrepository.com/artifact/org.apache.kafka/kafka-streams-test-utils)

* TopologyTestDriver
* OutputVerifier
* Supports punctuations (manually advance wall clock time)
* Direct access to state stores

```notes
https://kafka.apache.org/11/documentation/streams/developer-guide/testing.html

* pipe data through Topology (PAPI or Streams DSL)
* simulates the library runtime that continuously fetches records from input topics and processes them by traversing the topology. 
* use to verify topology computes correct output. very functional.
* captures the results records and allows to query its embedded state stores.
* OutputVerifier - assert on portions of output record
```

---

<CodeSurfer
  code={require("raw-loader!./snippets/ktable.java")}
  language="java"
  title="Users KTable"
  steps={[
    { range: [ 1,  16] },
    { range: [5, 6], notes: "Look familiar? Inject instead of instantiate"},
    { range: [8, 14], notes: "Records from user-updates go into users ktable"}
  ]}
/>

---

<CodeSurfer
  code={require("raw-loader!./snippets/ktablespec.groovy")}
  language="groovy"
  title="Users KTable Spec - Topology Driver"
  steps={[
    { range: [ 1,  29] },
    { range: [8, 14], notes: "Configure a serde utilizing the MockSchemaRegistryClient"},
    { range: [16, 19], notes: "Setup a record factory for tests to use"},
    { range: [21, 29], notes: "Configure StreamBuilder and TopologyTestDriver"},
    { range: [32, 56], notes: "Test 1: Published record ends up in ktable"},
    { range: [33, 45] },
    { range: [47, 48] },
    { range: [50, 55] },
    { range: [58, 85], notes: "Test 2: Update an existing ktable entry"},
    { range: [59, 67] },
    { range: [69, 78] },
    { range: [80, 84] }
  ]}
/>

---

## [Spring Kafka Test](https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka-test)

* Embedded Kafka
* Embedded ZooKeeper
* KafkaTestUtils
* [No Schema Registry Support](https://objectpartners.com/2018/08/21/testing-with-spring-kafka-and-mockschemaregistryclient)

```notes
* `spring.embedded.kafka.brokers` set to broker address 
* broker count, topics, partitions, other props
* `spring.embedded.zookeeper.connect` set to zk address
* KafkaTestUtils - client configuration helpers

https://github.com/spring-projects/spring-kafka/blob/master/src/reference/asciidoc/testing.adoc
```
---

<ContainImage src='./assets/4-pyramid-e2e.png' />

---

## When to go E2E?

<h3>It depends...</h3>
<ul style={{textAlign: 'left', marginLeft: '3em'}}>
  <Appear>
    <li>environment</li>
    <li>resources</li>
    <li>app architecture</li>
    <li>team goals</li>
    <li>value of E2E</li>
  </Appear>
</ul>


```notes
I have found that this portion of the testing ecosystem is so 
dependent on the application on hand and varies so much that I 
didn‚Äôt dive too deep into this. Also, this layer of testing for a 
kafka environment starts to look a lot like integration testing++. 
You just need to figure out the best way to create a more realistic 
environment to target. Based on infrastructure availability and other 
needs this can be so different for every org.
```

---

## Success Measures

<ul style={{listStyleType: 'none', textAlign: 'left', marginLeft: '2em', fontSize: '1.5em'}}>
  <Appear>
    <li><Emoji symbol={'üéñÔ∏è'} label={'participation'} />: Here today &amp; starting tomorrow!</li>
    <li><Emoji symbol={'ü•â'} label={'bronze'} />: Unit tests are flowing</li>
    <li><Emoji symbol={'ü•à'} label={'silver'} />: Integration testing is happening</li>
    <li><Emoji symbol={'ü•á'} label={'gold'} />: You're into the E2E realm</li>
  </Appear>
</ul>

```notes
If you at the SFO summit, there was a great talk on chaos engineering your Kafka cluster and if you‚Äôre doing any of that I would also award you this medal.

* Participation Ribbon - You are here today because your team is starting this journey tomorrow!
* Participation Ribbon - You are here today because your team has no tests. Hey, that‚Äôs ok! You get this ribbon for participating and making the effort to learn about improving your process.
* Bronze - Unit tests are flowing and you're working towards hitting your team's goals.
* Bronze - The unit tests are flowing, but that‚Äôs about it. You‚Äôve hit your coverage mark and feel solid about the dependency of those tests to alert you quickly on any regression.
* Silver - Integration testing has started and your unit tests are under control.
* Silver - Integration testing is a part of the pipeline and your team has a suite of isolated ‚Äúend to end‚Äù tests on an embedded broker or a docker-compose env or something similar.
* Gold - You should give this talk. You've gone full E2E and are bored with testing.
* Gold - You‚Äôre bored with unit and integration testing and put together full on end to end tests that simulate the exact env your code is running. Also, you should have just given this talk.
```
---

<https://github.com/msschroe3/testing-kafka-presentation>
